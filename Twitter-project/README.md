---------------PROJECT OVERVIEW-----------

The dataset that you will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because "they're good dogs Brent." WeRateDogs has over 4 million followers and has received international media coverage.

The tasks for the project include:
Step 1: Gathering data

Step 2: Assessing data

Step 3: Cleaning data

Step 4: Storing data

Step 5: Analyzing, and visualizing data

Step 6: Reporting
   your data wrangling efforts
   your data analyses and visualizations

----------------CONTEXT OF THE PROJECT----------

The goal is to wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. The Twitter archive is great, but it only contains very basic tweet information. Additional gathering, then assessing and cleaning is required for "Wow!"-worthy analyses and visualizations.

------------------DATASETS-----------------------

(I) Enhanced Twitter Archive.
(II) Additinal Data via the Twitter API.
(III) Image Prediction File.

----------------FILES IN THE WORKSPACE--------

wrangle_act.ipynb: code for gathering, assessing, cleaning, analyzing, and visualizing data.

wrangle_report.pdf or wrangle_report.html: documentation for data wrangling steps: gather, assess, and clean.

act_report.pdf or act_report.html: documentation of analysis and insights into final data.

twitter_archive_enhanced.csv: file as given.

image_predictions.tsv: file downloaded programmatically.

tweet_json.txt: file constructed via API.

twitter_archive_master.csv: combined and cleaned data.

any additional files (e.g. files for additional pieces of gathered data or a database file for your stored clean data)
